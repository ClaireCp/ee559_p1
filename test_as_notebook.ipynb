{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working with 1channel2images framework, nb_classes =  10\n",
      "Training complete in 0 min 2 s\n",
      "Best val acc: 0.9715\n",
      "Training complete in 0 min 2 s\n",
      "Best val acc: 0.9755\n",
      "Overwriting file\n",
      "For model BaseNet1C, mean test accuracy = 0.9375\n",
      "Training complete in 0 min 23 s\n",
      "Best val acc: 0.9965\n",
      "Training complete in 0 min 24 s\n",
      "Best val acc: 0.9965\n",
      "Overwriting file\n",
      "For model ConvNet1_1C, mean test accuracy = 0.975\n",
      "Working with 2channels1image framework, nb_classes =  1\n",
      "Training complete in 0 min 2 s\n",
      "Best val acc: 0.9890\n",
      "Training complete in 0 min 2 s\n",
      "Best val acc: 0.9930\n",
      "For model BaseNet2C, mean test accuracy = 0.788\n",
      "Training complete in 0 min 31 s\n",
      "Best val acc: 0.9960\n",
      "Training complete in 0 min 30 s\n",
      "Best val acc: 1.0000\n",
      "For model ConvNet1_2C, mean test accuracy = 0.842\n",
      "Training complete in 0 min 22 s\n",
      "Best val acc: 0.9790\n",
      "Training complete in 0 min 23 s\n",
      "Best val acc: 0.9940\n",
      "For model ConvNet2_2C, mean test accuracy = 0.7865\n",
      "Training complete in 0 min 13 s\n",
      "Best val acc: 0.8730\n",
      "Training complete in 0 min 13 s\n",
      "Best val acc: 0.9220\n",
      "For model ConvNet4_2C, mean test accuracy = 0.807\n",
      "Working with weight_sharing framework\n",
      "Training complete in 1 min 4 s\n",
      "Best val acc: 1.0000\n",
      "Training complete in 1 min 8 s\n",
      "Best val acc: 1.0000\n",
      "For model NetSharing1, mean test accuracy = 0.8494999999999999\n",
      "Training complete in 0 min 46 s\n",
      "Best val acc: 0.9830\n",
      "Training complete in 0 min 44 s\n",
      "Best val acc: 0.9800\n",
      "For model NetSharing2, mean test accuracy = 0.8614999999999999\n",
      "Training complete in 0 min 35 s\n",
      "Best val acc: 0.9330\n",
      "Training complete in 0 min 39 s\n",
      "Best val acc: 0.8460\n",
      "For model NetSharing3, mean test accuracy = 0.8374999999999999\n",
      "Training complete in 0 min 23 s\n",
      "Best val acc: 0.9230\n",
      "Training complete in 0 min 24 s\n",
      "Best val acc: 0.9160\n",
      "For model NetSharing4, mean test accuracy = 0.8474999999999999\n",
      "Working with auxiliary_losses framework\n",
      "Training complete in 0 min 51 s\n",
      "Best val acc: 0.8570\n",
      "Training complete in 0 min 55 s\n",
      "Best val acc: 0.8920\n",
      "For model Incept4, mean test accuracy = 0.8365\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Relevant imports and global variables \"\"\"\n",
    "import torch\n",
    "torch.manual_seed(1234)\n",
    "from generic_helpers import *\n",
    "import sys\n",
    "\n",
    "mini_batch_size = 250\n",
    "nb_runs = 2\n",
    "lr = 0.01\n",
    "\n",
    "######### _1CHANNEL2IMAGES #############################################################\n",
    "sys.path.insert(0, \"channelimagesModels\")\n",
    "from BaseNet import *\n",
    "from ConvNet1 import *\n",
    "import _1channel2images\n",
    "from _1channel2images import *\n",
    "print(\"Working with 1channel2images framework, nb_classes = \", nb_classes)\n",
    "\n",
    "#model1C_list = []\n",
    "model1C_list = [BaseNet1C(), ConvNet1_1C()]\n",
    "nb_epochs = 30\n",
    "for model_1C in model1C_list:\n",
    "    test_results_1C = multiple_training_runs_1C(model_1C, nb_runs, lr, mini_batch_size, nb_epochs, verbose=False)\n",
    "    write_to_csv_1C('1channel2images.csv', model_1C, test_results_1C, lr, nb_epochs)\n",
    "    print(\"For model {}, mean test accuracy = {}\".format(model_1C.name, test_results_1C[6]))\n",
    "    \n",
    "    \n",
    "######### _2CHANNELS1IMAGE #############################################################\n",
    "import _2channels1image\n",
    "from _2channels1image import *\n",
    "print(\"Working with 2channels1image framework, nb_classes = \", nb_classes)\n",
    "#model2C_list = []\n",
    "model2C_list = [BaseNet2C(), ConvNet1_2C(), ConvNet2_2C(), ConvNet4_2C()]\n",
    "nb_epochs = 75\n",
    "for model_2C in model2C_list:\n",
    "    test_results_2C = multiple_training_runs_fn(model_2C, train_model_2C, test_model_2C, title_2C, nb_runs, lr, mini_batch_size, nb_epochs, verbose=False)\n",
    "    write_to_csv('2channels1image.csv', model_2C, test_results_2C, lr, nb_epochs)\n",
    "    print(\"For model {}, mean test accuracy = {}\".format(model_2C.name, test_results_2C[4]))\n",
    "    \n",
    "    \n",
    "######### WEIGHT_SHARING ###############################################################\n",
    "sys.path.insert(0, \"weightssharingModels\")\n",
    "from NetSharing import *\n",
    "from weight_sharing import *\n",
    "print(\"Working with weight_sharing framework\")\n",
    "#modelws_list = []\n",
    "modelws_list = [NetSharing1(), NetSharing2(), NetSharing3(), NetSharing4()]\n",
    "nb_epochs = 75\n",
    "for model_ws in modelws_list:\n",
    "    test_results_ws = multiple_training_runs_fn(model_ws, train_model_ws, test_model_ws, title_ws, nb_runs, lr, mini_batch_size, nb_epochs, verbose=False)\n",
    "    write_to_csv('weightsharing.csv', model_ws, test_results_ws, lr, nb_epochs)\n",
    "    print(\"For model {}, mean test accuracy = {}\".format(model_ws.name, test_results_ws[4]))\n",
    "\n",
    "    \n",
    "######### AUXILIARY_LOSSES #############################################################\n",
    "sys.path.insert(0, \"auxiliarylossesModels\")  \n",
    "from Incept import *\n",
    "from auxiliary_losses import *\n",
    "print(\"Working with auxiliary_losses framework\")\n",
    "#modelaux_list = []\n",
    "modelaux_list = [Incept1a(), Incept1b(), Incept2(), Incept3(), Incept4()]\n",
    "#modelaux_list = [Incept4()]\n",
    "nb_epochs = 150\n",
    "for model_aux in modelaux_list:\n",
    "    test_results_aux = multiple_training_runs_fn(model_aux, train_model_aux, test_model_aux, title_aux, nb_runs, lr, mini_batch_size, nb_epochs, verbose=False)\n",
    "    write_to_csv('auxiliary_losses.csv', model_aux, test_results_aux, lr, nb_epochs)\n",
    "    print(\"For model {}, mean test accuracy = {}\".format(model_aux.name, test_results_aux[4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
